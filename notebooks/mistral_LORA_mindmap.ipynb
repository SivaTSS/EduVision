{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a77d101-1bf6-406c-9e3b-795eb609c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b394b49f-f1cb-4825-87e8-32a58652c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load keys and set token\n",
    "with open(\"../keys.json\", \"r\") as file:\n",
    "    token_data = json.load(file)\n",
    "HUGGINGFACE_TOKEN = token_data[\"huggingface_access_token\"]\n",
    "os.environ[\"HF_TOKEN\"] = HUGGINGFACE_TOKEN \n",
    "\n",
    "# Define model checkpoint and directories\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "scratch_dir = \"../models\"\n",
    "\n",
    "# Create a BitsAndBytesConfig for 4-bit quantization.\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48586d9e-78c7-4417-adfc-2eae93814645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c5fec2b587437d91dc635dd1d36d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=scratch_dir)\n",
    "\n",
    "# Load the model in 4-bit mode using quantization_config\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=scratch_dir,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ee583b-f9f9-43a5-8bfb-9e205815cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the LoRA configuration; parameters can be tuned as needed.\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # adjust based on model architecture\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "# Wrap the 4-bit quantized model with LoRA adapter using QLoRA.\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b37f1-5741-470a-9960-531fbc829ba1",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c163fef8-d22c-4bb7-a218-ff513a20c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_textbook_text_with_image_explainations(entry):\n",
    "    texts = []\n",
    "    lesson_name = entry.get(\"lessonName\", \"\")\n",
    "    if lesson_name:\n",
    "        texts.append(f\"Lesson: {lesson_name.strip()}\")\n",
    "    \n",
    "    base_dir = \"../data/tqa_train_val_test/train/\"\n",
    "    \n",
    "    def extract_content_and_explanations(section):\n",
    "        section_texts = []\n",
    "        content = section.get(\"content\", {})\n",
    "        text = content.get(\"text\", \"\")\n",
    "        if text:\n",
    "            section_texts.append(text.strip())\n",
    "        figures = content.get(\"figures\", [])\n",
    "        for fig in figures:\n",
    "            caption = fig.get(\"caption\", \"\").strip()\n",
    "            image_path = fig.get(\"imagePath\", \"\")\n",
    "            if image_path:\n",
    "                if \"textbook_images\" in image_path:\n",
    "                    explanation_folder = \"textbook_images_llava_captions\"\n",
    "                elif \"teaching_images\" in image_path:\n",
    "                    explanation_folder = \"teaching_images_llava_captions\"\n",
    "                else:\n",
    "                    explanation_folder = None\n",
    "                if explanation_folder:\n",
    "                    file_name = os.path.basename(image_path)\n",
    "                    base_name = os.path.splitext(file_name)[0]\n",
    "                    explanation_file = os.path.join(base_dir, explanation_folder, base_name + \".txt\")\n",
    "                    if os.path.exists(explanation_file):\n",
    "                        with open(explanation_file, 'r', encoding=\"utf-8\") as f:\n",
    "                            explanation = f.read().strip()\n",
    "                        if explanation:\n",
    "                            combined_text = \"\"\n",
    "                            if caption:\n",
    "                                combined_text += f\"Image Caption: {caption}. \"\n",
    "                            combined_text += f\"Image Explanation: {explanation}\"\n",
    "                            section_texts.append(combined_text)\n",
    "        return section_texts\n",
    "\n",
    "    adjunct_topics = entry.get(\"adjunctTopics\", {})\n",
    "    for topic in adjunct_topics.values():\n",
    "        texts.extend(extract_content_and_explanations(topic))\n",
    "    \n",
    "    topics = entry.get(\"topics\", {})\n",
    "    for topic in topics.values():\n",
    "        texts.extend(extract_content_and_explanations(topic))\n",
    "    \n",
    "    return texts\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    name = name.strip().replace(\" \", \"_\")\n",
    "    return re.sub(r'[^A-Za-z0-9_-]', '', name)\n",
    "\n",
    "def create_training_example(entry, ground_truth_folder):\n",
    "    identifier = entry.get(\"globalID\", \"\")\n",
    "    if not identifier or not identifier.strip():\n",
    "        lesson_name = entry.get(\"lessonName\", \"\")\n",
    "        identifier = sanitize_filename(lesson_name) if lesson_name.strip() else f\"entry_unknown\"\n",
    "    \n",
    "    extracted_texts = extract_textbook_text_with_image_explainations(entry)\n",
    "    combined_text = \"\\n\\n\".join(extracted_texts)\n",
    "    if not combined_text.strip():\n",
    "        return None\n",
    "    \n",
    "    gt_file = os.path.join(ground_truth_folder, f\"mermaid_code_{identifier}.txt\")\n",
    "    if not os.path.exists(gt_file):\n",
    "        print(f\"Ground truth file not found for identifier {identifier} at {gt_file}\")\n",
    "        return None\n",
    "    \n",
    "    with open(gt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        ground_truth_mindmap = f.read().strip()\n",
    "    \n",
    "    training_text = (\n",
    "        \"Instruction: Generate a mind map in Mermaid syntax for the following textbook text. \"\n",
    "        \"The mind map should capture the main topics and their subtopics clearly in a hierarchical structure. \"\n",
    "        \"Ensure that there is exactly one central (root) node, which is the only root, and attach all other topics \"\n",
    "        \"as subtopics of this central node. Do NOT include a 'root' node with a generic label; instead, use a relevant central topic. \"\n",
    "        \"Also, do NOT include any theme directives such as %%{init: {\\\"theme\\\": \\\"default\\\"}}%%, any parentheses or any extraneous formatting. \"\n",
    "        \"The mind map should be self-explanatory so that by reading it, a user can understand the key content and structure \"\n",
    "        \"of the text document. Keep the Mermaid syntax minimal so it renders correctly, and be concise.\\n\\n\"\n",
    "        f\"Input: {combined_text}\\n\"\n",
    "        f\"Output: {ground_truth_mindmap}\"\n",
    "    )\n",
    "    return {\"text\": training_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142223ce-fa0d-4fa9-888d-04e3059e6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing training examples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 666/666 [00:00<00:00, 6058.07it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# Load and prepare training data\n",
    "# ----------------------------\n",
    "train_data_path = \"../data/tqa_train_val_test/train/tqa_v1_train.json\"\n",
    "with open(train_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_entries = json.load(f)\n",
    "\n",
    "dataset_folder = os.path.dirname(train_data_path)\n",
    "ground_truth_folder = os.path.join(dataset_folder, \"mindmap_text\")\n",
    "\n",
    "train_examples = []\n",
    "for i, entry in tqdm(enumerate(train_entries), total=len(train_entries), desc=\"Preparing training examples\"):\n",
    "    try:\n",
    "        example = create_training_example(entry, ground_truth_folder)\n",
    "        if example is not None:\n",
    "            train_examples.append(example)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing training entry {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "if not train_examples:\n",
    "    raise ValueError(\"No training examples were created. Check your ground truth folder and JSON data.\")\n",
    "\n",
    "train_dataset = Dataset.from_list(train_examples)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fc169d-e36e-44bb-bfb2-9a5e47fc306c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb72abde50848169258a00196da2934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/666 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "##########################################\n",
    "# Tokenize and mask prompt tokens\n",
    "##########################################\n",
    "def tokenize_function(examples):\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    labels_list = []\n",
    "    max_length = 5000\n",
    "\n",
    "    for full_text in examples[\"text\"]:\n",
    "        split_text = full_text.split(\"Output:\")\n",
    "        if len(split_text) == 2:\n",
    "            prompt_part = split_text[0] + \"Output:\"  # Include the marker\n",
    "            tokenized_full = tokenizer(full_text, truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "            # Tokenize the prompt WITHOUT truncation to get the true prompt length.\n",
    "            tokenized_prompt = tokenizer(prompt_part, add_special_tokens=False, truncation=False)\n",
    "            prompt_length = len(tokenized_prompt[\"input_ids\"])\n",
    "            labels = tokenized_full[\"input_ids\"].copy()\n",
    "            if prompt_length < max_length:\n",
    "                labels[:prompt_length] = [-100] * prompt_length\n",
    "            else:\n",
    "                # If prompt is too long, don't mask (or consider skipping this example)\n",
    "                pass\n",
    "        else:\n",
    "            tokenized_full = tokenizer(full_text, truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "            labels = tokenized_full[\"input_ids\"].copy()\n",
    "        \n",
    "        def pad_and_truncate(seq, pad_value, length):\n",
    "            if len(seq) < length:\n",
    "                return seq + [pad_value] * (length - len(seq))\n",
    "            return seq[:length]\n",
    "        \n",
    "        input_ids = pad_and_truncate(tokenized_full[\"input_ids\"], tokenizer.pad_token_id, max_length)\n",
    "        attention_mask = pad_and_truncate(tokenized_full[\"attention_mask\"], 0, max_length)\n",
    "        labels = pad_and_truncate(labels, -100, max_length)\n",
    "        \n",
    "        input_ids_list.append(input_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        labels_list.append(labels)\n",
    "        \n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"attention_mask\": attention_mask_list,\n",
    "        \"labels\": labels_list,\n",
    "    }\n",
    "\n",
    "tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6889a244-9f04-4bde-bf15-094b2e72f6ec",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c8d8aa-1821-4609-98b4-56d38d4d425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Training Setup\n",
    "##########################################\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_mistral_mindmaps\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    evaluation_strategy=\"no\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67f8d84-fb38-4d1f-9c0b-a1510effc041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 51:07, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>21.670200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.503800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "##########################################\n",
    "# Train and Save the Model\n",
    "##########################################\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./lora_mistral_adapter_mindmaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6164f755-1b38-4d68-bd03-b5e12bad314a",
   "metadata": {},
   "source": [
    "## Testing just Mistral7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "266aeb09-d5ca-4a62-b4f7-ba858ec472ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define model name and cache directory\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "scratch_dir = \"../models\"\n",
    "\n",
    "# Create the quantization configuration (same as used during training)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12036779-072c-41bc-bae5-eed13379f267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242316a2d0e14eff88b5d40e17e566e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=scratch_dir)\n",
    "\n",
    "# Load the base model with 4-bit quantization (without LoRA adapter)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=scratch_dir,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "# Load the test dataset JSON file.\n",
    "test_data_path = \"../data/tqa_train_val_test/test/tqa_v2_test.json\"\n",
    "with open(test_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_entries = json.load(f)\n",
    "\n",
    "# Define the dataset folder and ground truth folder if needed\n",
    "dataset_folder = os.path.dirname(test_data_path)\n",
    "ground_truth_folder = os.path.join(dataset_folder, \"mindmap_text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "280940c5-145d-4419-8c31-d7b38bbf5a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Create the test prompt from an entry\n",
    "def create_test_prompt(entry):\n",
    "    extracted_texts = extract_textbook_text_with_image_explainations(entry)\n",
    "    combined_text = \"\\n\\n\".join(extracted_texts)\n",
    "    prompt = (\n",
    "         \"Instruction: Generate a mind map in Mermaid syntax for the following textbook text. \"\n",
    "         \"The mind map should capture the main topics and their subtopics clearly in a hierarchical structure. \"\n",
    "         \"Ensure that there is exactly one central (root) node, which is the only root, and attach all other topics \"\n",
    "         \"as subtopics of this central node. Do NOT include a 'root' node with a generic label; instead, use a relevant central topic. \"\n",
    "         \"Also, do NOT include any theme directives such as %%{init: {\\\"theme\\\": \\\"default\\\"}}%%, any parentheses or any extraneous formatting. \"\n",
    "         \"The mind map should be self-explanatory so that by reading it, a user can understand the key content and structure \"\n",
    "         \"of the text document. Keep the Mermaid syntax minimal so it renders correctly, and be concise.\\n\\n\"\n",
    "         f\"Input: {combined_text}\\n\"\n",
    "         \"Output:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# Set up the text-generation pipeline using the base model\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adbc1452-9b97-45f9-af2a-9b78c6342cfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample Prompt ===\n",
      "Instruction: Generate a mind map in Mermaid syntax for the following textbook text. The mind map should capture the main topics and their subtopics clearly in a hierarchical structure. Ensure that there is exactly one central (root) node, which is the only root, and attach all other topics as subtopics of this central node. Do NOT include a 'root' node with a generic label; instead, use a relevant central topic. Also, do NOT include any theme directives such as %%{init: {\"theme\": \"default\"}}%%, any parentheses or any extraneous formatting. The mind map should be self-explanatory so that by reading it, a user can understand the key content and structure of the text document. Keep the Mermaid syntax minimal so it renders correctly, and be concise.\n",
      "\n",
      "Input: Lesson: the nature of science\n",
      "\n",
      "3. Write five questions that would get a friend interested in exploring the natural world. 4. A scientist was studying the effects of oil contamination on ocean seaweed. He believed that oil runoff from storm drains would keep seaweed from growing normally. He had two large aquarium tanks of equal size. He kept the amount of dissolved oxygen and the water temperature the same in each tank. He added some motor oil to one tank but not to the other. He then measured the growth of seaweed plants in each tank. In the tank with no oil, the average growth was 2.57cm/day. The average growth of the seaweed in the tank with oil was 2.37cm/day. Based on this experiment, answer the following questions: What was the question that the scientist started with? What was his hypothesis? Identify the independent variable, the dependent variable, and the experimental control(s). What did the data show?\n",
      "\n",
      "Sometime in your life youve asked a question about the world around you. Probably youve asked a lot of questions over the years. The best way to answer questions about the natural world is by using science. Scientists ask questions every day, and then use a set of steps to answer those questions. The steps are known as the scientific method. By following the scientific method, scientists come up with the best information about the natural world. As a scientist, you need to do experiments to find out about the world. You also need to wonder, observe, talk, and think. Everything we learn helps us to ask new and better questions.\n",
      "\n",
      "Why is it important to ask questions?\n",
      "How can you use the steps of the scientific method to answer questions?\n",
      "How do scientists make models?\n",
      "What steps should you take to be safe while you are doing science?\n",
      "I\n",
      "\n",
      "Scientists ask questions about the natural world. Scientific method is a set of logical steps that can be used to answer these questions. A hypothesis is a reasonable explanation of something. A theory is a hypothesis that has been shown to be true many times over. Models represent real things but are simpler. If you are working in a lab, it is very important to be safe.\n",
      "\n",
      "What parts of Earth do you think are most important and should be better studied? Describe a model that you have had experience with. What type of model was it? What did you learn from it? What situations are both necessary and dangerous for scientists to study? What precautions do you think they should use when they study them? If you could go anywhere, where would it be? What safety equipment or precautions would you take?\n",
      "\n",
      "1. Describe three types of scientific models. Under what circumstances would each be used? 2. If you have access to a science laboratory, look around to see what safety symbols there are. What does each mean?\n",
      "\n",
      "5. Design your own experiment based on one of your questions from question 3 above. Include the question, hypothesis, independent and dependent variables, and safety precautions.\n",
      "\n",
      "The scientific method is a set of steps that help us to answer questions. When we use logical steps and control the number of things that can be changed, we get better answers. As we test our ideas, we may come up with more questions. The basic sequence of steps followed in the scientific method is illustrated in Figure 1.1.\n",
      "\n",
      "Asking a question is one really good way to begin to learn about the natural world. You might have seen something that makes you curious. You might want to know what to change to produce a better result. Lets say a farmer is having an erosion problem. She wants to keep more soil on her farm. The farmer learns that a farming method called no-till farming allows farmers to plant seeds without plowing the land. She wonders if planting seeds without plowing will reduce the erosion problem and help keep more soil on her farmland. Her question is this: Will using the no-till method of farming help me to lose less soil on my farm? (Figure 1.2).\n",
      "\n",
      "Before she begins, the farmer needs to learn more about this farming method. She can look up information in books and magazines in the library. She may also search the Internet. A good way for her to learn is to talk to people who have tried this way of farming. She can use all of this information to figure out how she is going to test her question about no-till farming. Farming machines are shown in the Figure 1.3.\n",
      "\n",
      "After doing the research, the farmer will try to answer the question. She might think, If I dont plow my fields, I will lose less soil than if I do plow the fields. Plowing disrupts the soil and breaks up roots that help hold soil in place. This answer to her question is a hypothesis. A hypothesis is a reasonable explanation. A hypothesis can be tested. It may be the right answer, it may be a wrong answer, but it must be testable. Once she has a hypothesis, the next step is to do experiments to test the hypothesis. A hypothesis can be proved or disproved by testing. If a hypothesis is repeatedly tested and shown to be true, then scientists call it a theory.\n",
      "\n",
      "When we design experiments, we choose just one thing to change. The thing we change is called the independent variable. In the example, the farmer chooses two fields and then changes only one thing between them. She changes how she plows her fields. One field will be tilled and one will not. Everything else will be the same on both fields: the type of crop she grows, the amount of water and fertilizer that she uses, and the slope of the fields she plants on. The fields should be facing the same direction to get about the same amount of sunlight. These are the experimental controls. If the farmer only changes how she plows her fields, she can see the impact of the one change. After the experiment is complete, scientists then measure the result. The farmer measures how much soil is lost from each field. This is the dependent variable. How much soil is lost from each field depends on the plowing method.\n",
      "\n",
      "During an experiment, a scientist collects data. The data might be measurements, like the farmer is taking in Figure labeled. Labeling helps the scientist to know what each number represents. A scientist may also write descriptions of what happened during the experiment. At the end of the experiment the scientist studies the data. The scientist may create a graph or drawing to show the data. If the scientist can picture the data the results may be easier to understand. Then it is easier to draw logical conclusions. Even if the scientist is really careful it is possible to make a mistake. One kind of mistake is with the equipment. For example, an electronic balance may always measure one gram high. To fix this, the balance should be adjusted. If it cant be adjusted, each measurement should be corrected. A mistake can come if a measurement is hard to make. For example, the scientist may stop a stopwatch too soon or too late. To fix this, the scientist should run the experiment many times and make many measurements. The average of the measurements will be the accurate answer. Sometimes the result from one experiment is very different from the other results. If one data point is really different, it may be thrown out. It is likely a mistake was made in that experiment.\n",
      "\n",
      "The scientist must next form a conclusion. The scientist must study all of the data. What statement best explains the data? Did the experiment prove the hypothesis? Sometimes an experiment shows that a hypothesis is correct. Other times the data disproves the hypothesis. Sometimes its not possible to tell. If there is no conclusion, the scientist may test the hypothesis again. This time he will use some different experiments. No matter what the experiment shows the scientist has learned something. Even a disproved hypothesis can lead to new questions. The farmer grows crops on the two fields for a season. She finds that 2.2 times as much soil was lost on the plowed field as compared to the unplowed field. She concludes that her hypothesis was correct. The farmer also notices some other differences in the two plots. The plants in the no-till plots are taller. The soil moisture seems higher. She decides to repeat the experiment. This time she will measure soil moisture, plant growth, and the total amount of water the plants consume. From now on she will use no-till methods of farming. She will also research other factors that may reduce soil erosion.\n",
      "\n",
      "When scientists have the data and conclusions, they write a paper. They publish their paper in a scientific journal. A journal is a magazine for the scientists who are interested in a certain field. Before the paper is printed, other scientists look at it to try to find mistakes. They see if the conclusions follow from the data. This is called peer review. If the paper is sound it is printed in the journal. Other papers are published on the same topic in the journal. The evidence for or against a hypothesis is discussed by many scientists. Sometimes a hypothesis is repeatedly shown to be true and never shown to be false. The hypothesis then becomes a theory. Sometimes people say they have a theory when what they have is a hypothesis. In science, a theory has been repeatedly shown to be true. A theory is supported by many observations. However, a theory may be disproved if conflicting data is discovered. Many important theories have been shown to be true by many observations and experiments and are extremely unlikely to be disproved. These include the theory of plate tectonics and the theory of evolution.\n",
      "\n",
      "Scientists use models to help them understand and explain ideas. Models explain objects or systems in a more simple way. Models often only show only a part of a system. The real situation is more complicated. Models help scientists to make predictions about complex systems. Some models are something that you can see or touch. Other types of models use an idea or numbers. Each type is useful in certain ways. Scientists create models with computers. Computers can handle enormous amounts of data. This can more accu- rately represent the real situation. For example, Earths climate depends on an enormous number of factors. Climate models can predict how climate will change as certain gases are added to the atmosphere. To test how good a model is, scientists might start a test run at a time in the past. If the model can predict the present it is probably a good model. It is more likely to be accurate when predicting the future.\n",
      "\n",
      "A physical model is a representation of something using objects. It can be three-dimensional, like a globe. It can also be a two-dimensional drawing or diagram. Models are usually smaller and simpler than the real object. They most likely leave out some parts, but contain the important parts. In a good model the parts are made or drawn to scale. Physical models allow us to see, feel and move their parts. This allows us to better understand the real system. An example of a physical model is a drawing of the layers of Earth (Figure 1.5). A drawing helps us to understand the structure of the planet. Yet there are many differences between a drawing and the real thing. The size of a model is much smaller, for example. A drawing also doesnt give good idea of how substances move. Arrows showing the direction the material moves can help. A physical model is very useful but it cant explain the real Earth perfectly.\n",
      "\n",
      "Some models are based on an idea that helps scientists explain something. A good idea explains all the known facts. An example is how Earth got its Moon. A Mars-sized planet hit Earth and rocky material broke off of both bodies (Figure 1.6). This material orbited Earth and then came together to form the Moon. This is a model of something that happened billions of years ago. It brings together many facts known from our studies of the Moons surface. It accounts for the chemical makeup of rocks from the Moon, Earth, and meteorites. The physical properties of Earth and Moon figure in as well. Not all known data fits this model, but much does. There is also more information that we simply dont yet know.\n",
      "\n",
      "Models may use formulas or equations to describe something. Sometimes math may be the only way to describe it. For example, equations help scientists to explain what happened in the early days of the universe. The universe formed so long ago that math is the only way to describe it. A climate model includes lots of numbers, including temperature readings, ice density, snowfall levels, and humidity. These numbers are put into equations to make a model. The results are used to predict future climate. For example, if there are more clouds, does global temperature go up or down? Models are not perfect because they are simple versions of the real situation. Even so, these models are very useful to scientists. These days, models of complex things are made on computers.\n",
      "\n",
      "Accidents happen from time to time in everyday life. Since science involves an adventure into the unknown, it is natural that accidents can happen. Therefore, we must be careful and use proper equipment to prevent accidents (Figure 1.7). We must also be sure to treat any injury or accident appropriately.\n",
      "\n",
      "If you work in the science lab, you may come across dangerous materials or situations. Sharp objects, chemicals, heat, and electricity are all used at times in science laboratories. With proper protection and precautions, almost all accidents can be prevented (Figure 1.8). If an accident happens, it can be dealt with appropriately. Below is a list of safety guidelines to follow when doing labs: Follow directions at all times. A science lab is not a play area. Be sure to obey all safety guidelines given in lab instructions or by the lab supervisor. Be sure to use the correct amount of each material. Tie back long hair. Wear closed shoes with flat heels. Shirts should have no hanging sleeves, hoods, or drawstrings. Use gloves, goggles, or safety aprons as instructed. Be very careful when you use sharp or pointed objects, such as knives. Clean up broken glass quickly with a dust pan and broom. Never touch broken glass with your bare hands. Never eat or drink in the science lab. Table tops and counters could have dangerous substances on them. Keep your work area neat and clean. A messy work area can lead to spills and breakage. Completely clean materials like test tubes and beakers. Leftover substances could interact with other sub- stances in future experiments. If you are using flames or heat plates, be careful when you reach. Be sure your arms and hair are kept far away from heat sources. Use electrical appliances and burners as instructed. Know how to use an eye wash station, fire blanket, fire extinguisher, and first aid kit. Alert the lab supervisor if anything unusual occurs. Fill out an accident report if someone is hurt. The lab supervisor must know if any materials are damaged or discarded.\n",
      "\n",
      "Many Earth science investigations are conducted in the field (Figure 1.9). Field work needs some additional precautions: Be sure to wear appropriate clothing. Hiking requires boots, long pants, and protection from the Sun, for example. Bring sufficient supplies like food and water, even for a short trip. Dehydration can occur rapidly. Take along first aid supplies. Let others know where you are going, what you will be doing, and when you will be returning. Take a map with you if you dont know the area and leave a copy of the map with someone at home. Try to have access to emergency services and some way to communicate. Beware that cell phones may not have coverage in all locations. Be sure that you are accompanied by a person familiar with the area or is familiar with field work.\n",
      "Output:\n",
      "=====================\n",
      "=== Generated Mind Map ===\n",
      "```mermaid\n",
      "graph LR\n",
      "  Scientific_method --> Question\n",
      "  Question --> Hypothesis\n",
      "  Question --> Model\n",
      "  Question --> Safety\n",
      "  Hypothesis --> Independent_variable\n",
      "  Hypothesis --> Dependent_variable\n",
      "  Hypothesis --> Experimental_control\n",
      "  Question --> Research\n",
      "  Question --> Talk\n",
      "  Question --> Observe\n",
      "  Question --> Wonder\n",
      "  Question --> Think\n",
      "  Question --> Repeat_experiment\n",
      "  Question --> Publish_paper\n",
      "  Question --> Theory\n",
      "  Question --> Disproved_hypothesis\n",
      "  Question --> New_questions\n",
      "  Question --> Data\n",
      "  Question --> Conclusion\n",
      "  Question --> Graph\n",
      "  Question --> Drawing\n",
      "  Question --> Physical_model\n",
      "  Question --> Idea_model\n",
      "  Question --> Formula_model\n",
      "  Question --> Computer_model\n",
      "  Question --> Accidents\n",
      "  Question --> Safety_guidelines\n",
      "  Question --> Injury\n",
      "  Question --> Accident_report\n",
      "  Question --> Damaged_materials\n",
      "  Question --> Field_work\n",
      "  Question --> Appropriate_clothing\n",
      "  Question --> Sufficient_supplies\n",
      "  Question --> First_aid_supplies\n",
      "  Question --> Let_others_know\n",
      "  Question --> Map\n",
      "  Question --> Emergency_services\n",
      "  Question --> Communication\n",
      "  Question --> Accompanied_by_\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "# Sample Inference Code\n",
    "\n",
    "# Choose a sample test entry (e.g., the first entry in your test dataset)\n",
    "sample_entry = test_entries[0]\n",
    "\n",
    "# Build the prompt using your test prompt function\n",
    "sample_prompt = create_test_prompt(sample_entry)\n",
    "print(\"=== Sample Prompt ===\")\n",
    "print(sample_prompt)\n",
    "print(\"=====================\")\n",
    "\n",
    "# Generate the mind map using the generation pipeline\n",
    "sample_output = generator(sample_prompt, max_new_tokens=300, do_sample=False)\n",
    "generated_text = sample_output[0][\"generated_text\"]\n",
    "\n",
    "# Extract the generated output portion after \"Output:\" marker (if present)\n",
    "if \"Output:\" in generated_text:\n",
    "    mindmap = generated_text.split(\"Output:\")[1].strip()\n",
    "else:\n",
    "    mindmap = generated_text.strip()\n",
    "\n",
    "print(\"=== Generated Mind Map ===\")\n",
    "print(mindmap)\n",
    "print(\"==========================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b7071-ee97-47ed-a5b8-5c635d8382e3",
   "metadata": {},
   "source": [
    "## Testing with QLORA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827f5766-0ebe-40c9-a00a-2d7baa9c2631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20efa4d54064b20be5d022644828e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# Define your model name and cache directory (if applicable)\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "scratch_dir = \"../models\"\n",
    "\n",
    "# Create the quantization configuration (same as used during training)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=scratch_dir)\n",
    "\n",
    "# Load the base model with 4-bit quantization\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=scratch_dir,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "# Load the LoRA adapter into the base model from the saved directory.\n",
    "# This wraps your base_model with the LoRA parameters.\n",
    "model = PeftModel.from_pretrained(base_model, \"./lora_mistral_adapter_mindmaps_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df166cd-3e0b-440e-8705-111006dbbb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the test dataset JSON file.\n",
    "test_data_path = \"../data/tqa_train_val_test/test/tqa_v2_test.json\"\n",
    "with open(test_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_entries = json.load(f)\n",
    "\n",
    "# Assume the test dataset's directory (you can also have a separate ground truth folder for test if available)\n",
    "dataset_folder = os.path.dirname(test_data_path)\n",
    "# Optionally, if you have ground truth mindmaps for test, define:\n",
    "ground_truth_folder = os.path.join(dataset_folder, \"mindmap_text\")\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def create_test_prompt(entry):\n",
    "    \"\"\"\n",
    "    Build the test prompt from an entry.\n",
    "    This uses the same extraction function and fixed instruction as in training,\n",
    "    but without including a ground truth output.\n",
    "    \"\"\"\n",
    "    extracted_texts = extract_textbook_text_with_image_explainations(entry)\n",
    "    combined_text = \"\\n\\n\".join(extracted_texts)\n",
    "    prompt = (\n",
    "         \"Instruction: Generate a mind map in Mermaid syntax for the following textbook text. \"\n",
    "         \"The mind map should capture the main topics and their subtopics clearly in a hierarchical structure. \"\n",
    "         \"Ensure that there is exactly one central (root) node, which is the only root, and attach all other topics \"\n",
    "         \"as subtopics of this central node. Do NOT include a 'root' node with a generic label; instead, use a relevant central topic. \"\n",
    "         \"Also, do NOT include any theme directives such as %%{init: {\\\"theme\\\": \\\"default\\\"}}%%, any parentheses or any extraneous formatting. \"\n",
    "         \"The mind map should be self-explanatory so that by reading it, a user can understand the key content and structure \"\n",
    "         \"of the text document. Keep the Mermaid syntax minimal so it renders correctly, and be concise.\\n\\n\"\n",
    "         f\"Input: {combined_text}\\n\"\n",
    "         \"Output:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25c92cf-605c-4c72-ad60-864d72ac5284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample Prompt ===\n",
      "Instruction: Generate a mind map in Mermaid syntax for the following textbook text. The mind map should capture the main topics and their subtopics clearly in a hierarchical structure. Ensure that there is exactly one central (root) node, which is the only root, and attach all other topics as subtopics of this central node. Do NOT include a 'root' node with a generic label; instead, use a relevant central topic. Also, do NOT include any theme directives such as %%{init: {\"theme\": \"default\"}}%%, any parentheses or any extraneous formatting. The mind map should be self-explanatory so that by reading it, a user can understand the key content and structure of the text document. Keep the Mermaid syntax minimal so it renders correctly, and be concise.\n",
      "\n",
      "Input: Lesson: the nature of science\n",
      "\n",
      "3. Write five questions that would get a friend interested in exploring the natural world. 4. A scientist was studying the effects of oil contamination on ocean seaweed. He believed that oil runoff from storm drains would keep seaweed from growing normally. He had two large aquarium tanks of equal size. He kept the amount of dissolved oxygen and the water temperature the same in each tank. He added some motor oil to one tank but not to the other. He then measured the growth of seaweed plants in each tank. In the tank with no oil, the average growth was 2.57cm/day. The average growth of the seaweed in the tank with oil was 2.37cm/day. Based on this experiment, answer the following questions: What was the question that the scientist started with? What was his hypothesis? Identify the independent variable, the dependent variable, and the experimental control(s). What did the data show?\n",
      "\n",
      "Sometime in your life youve asked a question about the world around you. Probably youve asked a lot of questions over the years. The best way to answer questions about the natural world is by using science. Scientists ask questions every day, and then use a set of steps to answer those questions. The steps are known as the scientific method. By following the scientific method, scientists come up with the best information about the natural world. As a scientist, you need to do experiments to find out about the world. You also need to wonder, observe, talk, and think. Everything we learn helps us to ask new and better questions.\n",
      "\n",
      "Why is it important to ask questions?\n",
      "How can you use the steps of the scientific method to answer questions?\n",
      "How do scientists make models?\n",
      "What steps should you take to be safe while you are doing science?\n",
      "I\n",
      "\n",
      "Scientists ask questions about the natural world. Scientific method is a set of logical steps that can be used to answer these questions. A hypothesis is a reasonable explanation of something. A theory is a hypothesis that has been shown to be true many times over. Models represent real things but are simpler. If you are working in a lab, it is very important to be safe.\n",
      "\n",
      "What parts of Earth do you think are most important and should be better studied? Describe a model that you have had experience with. What type of model was it? What did you learn from it? What situations are both necessary and dangerous for scientists to study? What precautions do you think they should use when they study them? If you could go anywhere, where would it be? What safety equipment or precautions would you take?\n",
      "\n",
      "1. Describe three types of scientific models. Under what circumstances would each be used? 2. If you have access to a science laboratory, look around to see what safety symbols there are. What does each mean?\n",
      "\n",
      "5. Design your own experiment based on one of your questions from question 3 above. Include the question, hypothesis, independent and dependent variables, and safety precautions.\n",
      "\n",
      "The scientific method is a set of steps that help us to answer questions. When we use logical steps and control the number of things that can be changed, we get better answers. As we test our ideas, we may come up with more questions. The basic sequence of steps followed in the scientific method is illustrated in Figure 1.1.\n",
      "\n",
      "Asking a question is one really good way to begin to learn about the natural world. You might have seen something that makes you curious. You might want to know what to change to produce a better result. Lets say a farmer is having an erosion problem. She wants to keep more soil on her farm. The farmer learns that a farming method called no-till farming allows farmers to plant seeds without plowing the land. She wonders if planting seeds without plowing will reduce the erosion problem and help keep more soil on her farmland. Her question is this: Will using the no-till method of farming help me to lose less soil on my farm? (Figure 1.2).\n",
      "\n",
      "Before she begins, the farmer needs to learn more about this farming method. She can look up information in books and magazines in the library. She may also search the Internet. A good way for her to learn is to talk to people who have tried this way of farming. She can use all of this information to figure out how she is going to test her question about no-till farming. Farming machines are shown in the Figure 1.3.\n",
      "\n",
      "After doing the research, the farmer will try to answer the question. She might think, If I dont plow my fields, I will lose less soil than if I do plow the fields. Plowing disrupts the soil and breaks up roots that help hold soil in place. This answer to her question is a hypothesis. A hypothesis is a reasonable explanation. A hypothesis can be tested. It may be the right answer, it may be a wrong answer, but it must be testable. Once she has a hypothesis, the next step is to do experiments to test the hypothesis. A hypothesis can be proved or disproved by testing. If a hypothesis is repeatedly tested and shown to be true, then scientists call it a theory.\n",
      "\n",
      "When we design experiments, we choose just one thing to change. The thing we change is called the independent variable. In the example, the farmer chooses two fields and then changes only one thing between them. She changes how she plows her fields. One field will be tilled and one will not. Everything else will be the same on both fields: the type of crop she grows, the amount of water and fertilizer that she uses, and the slope of the fields she plants on. The fields should be facing the same direction to get about the same amount of sunlight. These are the experimental controls. If the farmer only changes how she plows her fields, she can see the impact of the one change. After the experiment is complete, scientists then measure the result. The farmer measures how much soil is lost from each field. This is the dependent variable. How much soil is lost from each field depends on the plowing method.\n",
      "\n",
      "During an experiment, a scientist collects data. The data might be measurements, like the farmer is taking in Figure labeled. Labeling helps the scientist to know what each number represents. A scientist may also write descriptions of what happened during the experiment. At the end of the experiment the scientist studies the data. The scientist may create a graph or drawing to show the data. If the scientist can picture the data the results may be easier to understand. Then it is easier to draw logical conclusions. Even if the scientist is really careful it is possible to make a mistake. One kind of mistake is with the equipment. For example, an electronic balance may always measure one gram high. To fix this, the balance should be adjusted. If it cant be adjusted, each measurement should be corrected. A mistake can come if a measurement is hard to make. For example, the scientist may stop a stopwatch too soon or too late. To fix this, the scientist should run the experiment many times and make many measurements. The average of the measurements will be the accurate answer. Sometimes the result from one experiment is very different from the other results. If one data point is really different, it may be thrown out. It is likely a mistake was made in that experiment.\n",
      "\n",
      "The scientist must next form a conclusion. The scientist must study all of the data. What statement best explains the data? Did the experiment prove the hypothesis? Sometimes an experiment shows that a hypothesis is correct. Other times the data disproves the hypothesis. Sometimes its not possible to tell. If there is no conclusion, the scientist may test the hypothesis again. This time he will use some different experiments. No matter what the experiment shows the scientist has learned something. Even a disproved hypothesis can lead to new questions. The farmer grows crops on the two fields for a season. She finds that 2.2 times as much soil was lost on the plowed field as compared to the unplowed field. She concludes that her hypothesis was correct. The farmer also notices some other differences in the two plots. The plants in the no-till plots are taller. The soil moisture seems higher. She decides to repeat the experiment. This time she will measure soil moisture, plant growth, and the total amount of water the plants consume. From now on she will use no-till methods of farming. She will also research other factors that may reduce soil erosion.\n",
      "\n",
      "When scientists have the data and conclusions, they write a paper. They publish their paper in a scientific journal. A journal is a magazine for the scientists who are interested in a certain field. Before the paper is printed, other scientists look at it to try to find mistakes. They see if the conclusions follow from the data. This is called peer review. If the paper is sound it is printed in the journal. Other papers are published on the same topic in the journal. The evidence for or against a hypothesis is discussed by many scientists. Sometimes a hypothesis is repeatedly shown to be true and never shown to be false. The hypothesis then becomes a theory. Sometimes people say they have a theory when what they have is a hypothesis. In science, a theory has been repeatedly shown to be true. A theory is supported by many observations. However, a theory may be disproved if conflicting data is discovered. Many important theories have been shown to be true by many observations and experiments and are extremely unlikely to be disproved. These include the theory of plate tectonics and the theory of evolution.\n",
      "\n",
      "Scientists use models to help them understand and explain ideas. Models explain objects or systems in a more simple way. Models often only show only a part of a system. The real situation is more complicated. Models help scientists to make predictions about complex systems. Some models are something that you can see or touch. Other types of models use an idea or numbers. Each type is useful in certain ways. Scientists create models with computers. Computers can handle enormous amounts of data. This can more accu- rately represent the real situation. For example, Earths climate depends on an enormous number of factors. Climate models can predict how climate will change as certain gases are added to the atmosphere. To test how good a model is, scientists might start a test run at a time in the past. If the model can predict the present it is probably a good model. It is more likely to be accurate when predicting the future.\n",
      "\n",
      "A physical model is a representation of something using objects. It can be three-dimensional, like a globe. It can also be a two-dimensional drawing or diagram. Models are usually smaller and simpler than the real object. They most likely leave out some parts, but contain the important parts. In a good model the parts are made or drawn to scale. Physical models allow us to see, feel and move their parts. This allows us to better understand the real system. An example of a physical model is a drawing of the layers of Earth (Figure 1.5). A drawing helps us to understand the structure of the planet. Yet there are many differences between a drawing and the real thing. The size of a model is much smaller, for example. A drawing also doesnt give good idea of how substances move. Arrows showing the direction the material moves can help. A physical model is very useful but it cant explain the real Earth perfectly.\n",
      "\n",
      "Some models are based on an idea that helps scientists explain something. A good idea explains all the known facts. An example is how Earth got its Moon. A Mars-sized planet hit Earth and rocky material broke off of both bodies (Figure 1.6). This material orbited Earth and then came together to form the Moon. This is a model of something that happened billions of years ago. It brings together many facts known from our studies of the Moons surface. It accounts for the chemical makeup of rocks from the Moon, Earth, and meteorites. The physical properties of Earth and Moon figure in as well. Not all known data fits this model, but much does. There is also more information that we simply dont yet know.\n",
      "\n",
      "Models may use formulas or equations to describe something. Sometimes math may be the only way to describe it. For example, equations help scientists to explain what happened in the early days of the universe. The universe formed so long ago that math is the only way to describe it. A climate model includes lots of numbers, including temperature readings, ice density, snowfall levels, and humidity. These numbers are put into equations to make a model. The results are used to predict future climate. For example, if there are more clouds, does global temperature go up or down? Models are not perfect because they are simple versions of the real situation. Even so, these models are very useful to scientists. These days, models of complex things are made on computers.\n",
      "\n",
      "Accidents happen from time to time in everyday life. Since science involves an adventure into the unknown, it is natural that accidents can happen. Therefore, we must be careful and use proper equipment to prevent accidents (Figure 1.7). We must also be sure to treat any injury or accident appropriately.\n",
      "\n",
      "If you work in the science lab, you may come across dangerous materials or situations. Sharp objects, chemicals, heat, and electricity are all used at times in science laboratories. With proper protection and precautions, almost all accidents can be prevented (Figure 1.8). If an accident happens, it can be dealt with appropriately. Below is a list of safety guidelines to follow when doing labs: Follow directions at all times. A science lab is not a play area. Be sure to obey all safety guidelines given in lab instructions or by the lab supervisor. Be sure to use the correct amount of each material. Tie back long hair. Wear closed shoes with flat heels. Shirts should have no hanging sleeves, hoods, or drawstrings. Use gloves, goggles, or safety aprons as instructed. Be very careful when you use sharp or pointed objects, such as knives. Clean up broken glass quickly with a dust pan and broom. Never touch broken glass with your bare hands. Never eat or drink in the science lab. Table tops and counters could have dangerous substances on them. Keep your work area neat and clean. A messy work area can lead to spills and breakage. Completely clean materials like test tubes and beakers. Leftover substances could interact with other sub- stances in future experiments. If you are using flames or heat plates, be careful when you reach. Be sure your arms and hair are kept far away from heat sources. Use electrical appliances and burners as instructed. Know how to use an eye wash station, fire blanket, fire extinguisher, and first aid kit. Alert the lab supervisor if anything unusual occurs. Fill out an accident report if someone is hurt. The lab supervisor must know if any materials are damaged or discarded.\n",
      "\n",
      "Many Earth science investigations are conducted in the field (Figure 1.9). Field work needs some additional precautions: Be sure to wear appropriate clothing. Hiking requires boots, long pants, and protection from the Sun, for example. Bring sufficient supplies like food and water, even for a short trip. Dehydration can occur rapidly. Take along first aid supplies. Let others know where you are going, what you will be doing, and when you will be returning. Take a map with you if you dont know the area and leave a copy of the map with someone at home. Try to have access to emergency services and some way to communicate. Beware that cell phones may not have coverage in all locations. Be sure that you are accompanied by a person familiar with the area or is familiar with field work.\n",
      "Output:\n",
      "=====================\n",
      "=== Generated Mind Map ===\n",
      "mindmap\n",
      "  Nature of Science\n",
      "    Scientific Method\n",
      "      Asking Questions\n",
      "        Importance of Questions\n",
      "        Forming Hypotheses\n",
      "      Steps of Scientific Method\n",
      "        Experiment Design\n",
      "          Independent Variable\n",
      "          Dependent Variable\n",
      "          Experimental Controls\n",
      "        Data Collection\n",
      "          Measurements\n",
      "          Descriptions\n",
      "        Data Analysis\n",
      "          Graphing\n",
      "          Drawing Conclusions\n",
      "        Peer Review\n",
      "          Publication in Scientific Journals\n",
      "          Formation of Theories\n",
      "    Scientific Models\n",
      "      Types of Models\n",
      "        Physical Models\n",
      "          Globes\n",
      "          Drawings\n",
      "        Idea Models\n",
      "          Explanations of Phenomena\n",
      "        Mathematical Models\n",
      "          Climate Models\n",
      "      Importance of Models\n",
      "        Simplification of Complex Systems\n",
      "        Prediction of Future Events\n",
      "    Safety in Science\n",
      "      Importance of Safety\n",
      "        Prevention of Accidents\n",
      "      Safety Precautions\n",
      "        Use of Proper Equipment\n",
      "        Cleanliness\n",
      "      Field Safety\n",
      "        Clothing\n",
      "        Supplies\n",
      "        Communication\n",
      "    Conclusion\n",
      "      Importance of Science\n",
      "      Continuous Learning\n",
      "      Encouragement of Questions\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "# Sample Inference Code\n",
    "\n",
    "# Choose a sample test entry (e.g., the first entry in your test dataset)\n",
    "sample_entry = test_entries[0]  # assuming test_entries is already loaded\n",
    "\n",
    "# Build the prompt using your test prompt function\n",
    "sample_prompt = create_test_prompt(sample_entry)\n",
    "print(\"=== Sample Prompt ===\")\n",
    "print(sample_prompt)\n",
    "print(\"=====================\")\n",
    "\n",
    "# Generate the mind map using the generation pipeline\n",
    "sample_output = generator(sample_prompt, max_new_tokens=300, do_sample=False)\n",
    "generated_text = sample_output[0][\"generated_text\"]\n",
    "\n",
    "# Extract the generated output portion after \"Output:\" marker (if present)\n",
    "if \"Output:\" in generated_text:\n",
    "    mindmap = generated_text.split(\"Output:\")[1].strip()\n",
    "else:\n",
    "    mindmap = generated_text.strip()\n",
    "\n",
    "print(\"=== Generated Mind Map ===\")\n",
    "print(mindmap)\n",
    "print(\"==========================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac49624-b877-4e4f-b653-9d7a368ee4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create an output folder for individual prediction files\n",
    "predictions_folder = os.path.join(dataset_folder, \"test_predictions\")\n",
    "os.makedirs(predictions_folder, exist_ok=True)\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_entries), total=len(test_entries), desc=\"Generating predictions\"):\n",
    "    prompt = create_test_prompt(entry)\n",
    "    outputs = generator(prompt, max_new_tokens=300, do_sample=False)\n",
    "    generated_text = outputs[0][\"generated_text\"]\n",
    "    \n",
    "    # Extract only the generated output (after \"Output:\" marker)\n",
    "    if \"Output:\" in generated_text:\n",
    "        prediction = generated_text.split(\"Output:\")[1].strip()\n",
    "    else:\n",
    "        prediction = generated_text.strip()\n",
    "    \n",
    "    # Use the entry's identifier to create a unique filename\n",
    "    identifier = entry.get(\"globalID\", f\"entry_{i}\")\n",
    "    if not identifier or not identifier.strip():\n",
    "        lesson_name = entry.get(\"lessonName\", \"\")\n",
    "        identifier = lesson_name.strip().replace(\" \", \"_\") if lesson_name.strip() else f\"entry_{i}\"\n",
    "    # Sanitize identifier for filename safety.\n",
    "    identifier = \"\".join([c for c in identifier if c.isalnum() or c in \"_-\"])\n",
    "    \n",
    "    output_file = os.path.join(predictions_folder, f\"prediction_{identifier}.txt\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(prediction)\n",
    "        \n",
    "print(f\"Saved individual predictions to folder: {predictions_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393663da-1370-4834-9cd0-97ed004cf392",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ace0db-1d20-43aa-9fdb-af6d9a84c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_example(entry):\n",
    "    extracted_texts = extract_textbook_text_with_image_explainations(entry)\n",
    "    combined_text = \"\\n\\n\".join(extracted_texts)\n",
    "    if not combined_text.strip():\n",
    "        return None\n",
    "    # Create the prompt as in training, with a placeholder \"Output:\" marker.\n",
    "    prompt_text = (\n",
    "         \"Instruction: Generate a mind map in Mermaid syntax for the following textbook text. \"\n",
    "         \"The mind map should capture the main topics and their subtopics clearly in a hierarchical structure. \"\n",
    "         \"Ensure that there is exactly one central (root) node, which is the only root, and attach all other topics \"\n",
    "         \"as subtopics of this central node. Do NOT include a 'root' node with a generic label; instead, use a relevant central topic. \"\n",
    "         \"Also, do NOT include any theme directives such as %%{init: {\\\"theme\\\": \\\"default\\\"}}%%, any parentheses or any extraneous formatting. \"\n",
    "         \"The mind map should be self-explanatory so that by reading it, a user can understand the key content and structure \"\n",
    "         \"of the text document. Keep the Mermaid syntax minimal so it renders correctly, and be concise.\\n\\n\"\n",
    "         f\"Input: {combined_text}\\n\"\n",
    "         \"Output:\"\n",
    "    )\n",
    "    return {\"text\": prompt_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8759437c-1d97-4262-9938-f6e633e5eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = [create_test_example(entry) for entry in test_entries if create_test_example(entry)]\n",
    "if not test_examples:\n",
    "    raise ValueError(\"No valid test examples found.\")\n",
    "\n",
    "test_dataset = Dataset.from_list(test_examples)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312659bc-5ce6-465c-8ddd-268de85efc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a0d162ee0d4360839d118c3a377360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def tokenize_function(examples):\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    labels_list = []\n",
    "    max_length = 5000\n",
    "\n",
    "    for full_text in examples[\"text\"]:\n",
    "        tokenized_full = tokenizer(full_text, truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "        labels = tokenized_full[\"input_ids\"].copy()\n",
    "        input_ids_list.append(tokenized_full[\"input_ids\"])\n",
    "        attention_mask_list.append(tokenized_full[\"attention_mask\"])\n",
    "        labels_list.append(labels)\n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"attention_mask\": attention_mask_list,\n",
    "        \"labels\": labels_list,\n",
    "    }\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b75565e-f215-4030-be84-95ab44f2bbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 06:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3536030352115631\n",
      "Test Perplexity: 1.4241896867752075\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_mistral_mindmaps_eval\",\n",
    "    per_device_eval_batch_size=2,\n",
    ")\n",
    "\n",
    "eval_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    ")\n",
    "\n",
    "# Evaluate and print loss and perplexity.\n",
    "eval_results = eval_trainer.evaluate()\n",
    "eval_loss = eval_results.get(\"eval_loss\")\n",
    "print(f\"Test Loss: {eval_loss}\")\n",
    "\n",
    "if eval_loss is not None:\n",
    "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "    print(f\"Test Perplexity: {perplexity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b7105-b944-4fce-9054-1d2e94374f77",
   "metadata": {},
   "source": [
    "## Run on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6dc2aba-3933-4d94-b8b4-05ed7e46ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generated Mind Map ===\n",
      "```mermaid\n",
      "graph LR\n",
      "  Animation --> Animated_Logo\n",
      "  Animated_Logo --> Integration_with_Media\n",
      "  Integration_with_Media --> Videos\n",
      "  Integration_with_Media --> Livestreams\n",
      "  Integration_with_Media --> Websites\n",
      "  Integration_with_Media --> Social_Media\n",
      "  Animated_Logo --> Engagement\n",
      "  Animated_Logo --> Introduction\n",
      "  Animated_Logo --> Visual_Interest\n",
      "  Authoring_Animated_Logo --> Design_Elements\n",
      "  Authoring_Animated_Logo --> Sequence\n",
      "  Authoring_Animated_Logo --> Motion\n",
      "  Authoring_Animated_Logo --> Synchronization\n",
      "  Authoring_Animated_Logo --> Expertise\n",
      "  Design_Tools --> Templates\n",
      "  Design_Tools --> Automatic_Animation_Techniques\n",
      "  Design_Tools --> Adobe_Express\n",
      "  Design_Tools --> Canva\n",
      "  Design_Tools --> Figma\n",
      "  Templates --> Seamless_Look\n",
      "  Templates --> Edits\n",
      "  Templates --> Broken_Look\n",
      "  Automatic_Animation_Techniques --> Rules\n",
      "  Automatic_Animation_Techniques --> Heuristics\n",
      "  Emerging_Technologies --> LLMs\n",
      "  LLMs --> Content\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "# Sample Inference Code\n",
    "combined_text=\"\"\"\n",
    "Motion suggests life, and as such, motion is a dimension we add to our\n",
    "designs to make them more dynamic and engaging. Animation is a special\n",
    "type of design form which we have created to help us take static designs\n",
    "into more media-rich and interactive contexts. Aspecific type of animated \n",
    "content that we frequently create is the animated logo. \n",
    "\n",
    "Animation allows logos, which have been defined as the â€œvisual figureheads\" \n",
    "of brands [25], to better integrate within videos, livestreams, websites,\n",
    "and social media.\n",
    "\n",
    "A well-executed animation can quickly engage an audience, introduce the \n",
    "brand or individual online, and elevate content to have more visual interest.\n",
    "\n",
    "Authoring an animated logo is challenging. Logos are often more than just a \n",
    "pairing of icon with text. Because they can have different layouts, layers,\n",
    "color, and typography, they can take on great variety and be complex artifacts\n",
    "to animate.\n",
    "\n",
    "For a novice designer, it can be difficult to understand which design elements \n",
    "should be animated, in what sequence, and how to build up compelling and\n",
    "believable motion. There are many facets of motion to consider such as speed,\n",
    "timing, positioning, duration, easing, and motion personality\n",
    "(e.g. a playful bounce vs. a strong entrance). \n",
    "\n",
    "Additionally, when logos have more design elements, designers also have to\n",
    "understand how groups of elements can synchronize to coordinate motion and \n",
    "orchestrate a visual flow. While there is a great demand for animated content, \n",
    "it is diffi cult for people outside of motion design to develop this kind of\n",
    "expertise. \n",
    "\n",
    "Design tools such as Adobe Express, Canva, and Figma often provide \n",
    "solutions in the form of animated templates and au tomatic animation \n",
    "techniques [10, 12, 13]. Templates pre-populate logo layouts with animations\n",
    "that users can customize. They il lustrate how users can apply motion presets\n",
    "(e.g. slide, flicker, or fade) onto logo elements to create professional-looking\n",
    "animations. However, templates do not always adapt to every use case. \n",
    "\n",
    "When users make edits (e.g. add/remove/replace elements) to customize logo\n",
    "templates, they can easily break the seamless and professional look the\n",
    "templates were originally packaged with. An alternative to templates are\n",
    "automatic animation techniques, which globally apply rules and heuristics to\n",
    "animate canvases [12]. \n",
    "\n",
    "For example, all elements on a page can be directed to slide in from one side \n",
    "or 1Video: https://youtu.be/Jo9opkMH7iY 2Project P\n",
    "age: https://vivian-liu.com/#/logomotion sequentially fade into place.\n",
    "While templates and automatic tech niques can get users to a starting point fast,\n",
    "neither solution works with a recognition of the userâ€™s content,\n",
    "which is something that can be enabled by emerging technologies.\n",
    "Large language models (LLMs) present the potential for content aware animation.\n",
    "\n",
    "They can generate animation code that is specific to the design elements and their \n",
    "layout on the canvas. Code is a text representation that is often used to drive animation [18, 33, 53], because it can concisely specify how elements interact over time and space on a canvas. Because LLMs encode a vast amount of world knowledge, they can draw upon actions and activities related to the content being animated and generate a near infinite number of animations. This open-ended generative capacity can go beyond the scope of what templates, presets, and rule-based techniques usually cover. Recent advancements have made LLMs more multimodal, such that they can take in both text and image as inputs, and provide visually-grounded responses. This make LLMs more applicable in domains like animation where a visual understanding of the canvas matters. It opens upthepotentialforuserstoprovideimagesoftheir layout to an LLM and receive animations tailored to their layout and design elements. For example, if a novice designer wanted to animate a taxi, they could use an LLM to generate code to drive a taxi onto the canvas. This code could translate the taxi object along the x-axis before easing it into the center of the canvas to imply a stop-and-go motion befitting of taxis. In this paper, we present LogoMotion, an LLM-based method that automatically animates static layouts in a content-aware way. LogoMotion generates code in a two-stage approach involving visually-grounded program synthesis and program repair. The first stage introduces multimodal LLM operators that take in visual context andhandlethe1)constructionofatextrepresentationofthe canvas, 2) conceptual grouping of elements, and 3) implementation of animation code. The second stage of our approach introduces a technique for visually-grounded program repair, which helps LLMs check what they have generated against the original layout and debug differences in a targeted layer-wise fashion. Our contributions are as follows: â€¢ LogoMotion, an LLM system that uses visually-grounded code generation to automatically generate logo animations from a PDF. The system identifies the visual content in each layer, infers the primary and secondary elements, and cre ates groups of elements. Based on this, the system suggests a design concept (in text) and uses the LLM to generate ani mation code. Users can optionally improve the animation by editing or adding their own design concept. â€¢ Visually-grounded program repair, a mechanism that lets the LLM automatically detect and debug visual errors within its generated animation code, creating a feedback loop between LLM-generated code and its visual outputs. â€¢ Atechnical evaluation of 276 animations showing that com pared to Canva Magic Animate and an ablated version of the system (without stages for hierarchy analysis and de sign concept suggestions), the full pipeline of LogoMotion produces animations that are more content-aware. LogoMotion: Visually Grounded Code Generation for Content-Aware Animation Woodstock â€™18, June 03-05, 2018, Woodstock, NY â€¢ Aqualitative evaluation of novice users showing that Logo Motion is able to quickly achieve their desired animation with minimal reprompting.\n",
    "\"\"\"\n",
    "test_prompt = (\n",
    "     \"Instruction: Generate a mind map in Mermaid syntax for the following textbook text. \"\n",
    "     \"The mind map should capture the main topics and their subtopics clearly in a hierarchical structure. \"\n",
    "     \"Ensure that there is exactly one central (root) node, which is the only root, and attach all other topics \"\n",
    "     \"as subtopics of this central node. Do NOT include a 'root' node with a generic label; instead, use a relevant central topic. \"\n",
    "     \"Also, do NOT include any theme directives such as %%{init: {\\\"theme\\\": \\\"default\\\"}}%%, any parentheses or any extraneous formatting. \"\n",
    "     \"The mind map should be self-explanatory so that by reading it, a user can understand the key content and structure \"\n",
    "     \"of the text document. Keep the Mermaid syntax minimal so it renders correctly, and be concise.\\n\\n\"\n",
    "     f\"Input: {combined_text}\\n\"\n",
    "     \"Output:\"\n",
    ")\n",
    "\n",
    "# Generate the mind map using the generation pipeline\n",
    "sample_output = generator(test_prompt, max_new_tokens=300, do_sample=False)\n",
    "generated_text = sample_output[0][\"generated_text\"]\n",
    "\n",
    "# Extract the generated output portion after \"Output:\" marker (if present)\n",
    "if \"Output:\" in generated_text:\n",
    "    mindmap = generated_text.split(\"Output:\")[1].strip()\n",
    "else:\n",
    "    mindmap = generated_text.strip()\n",
    "\n",
    "print(\"=== Generated Mind Map ===\")\n",
    "print(mindmap)\n",
    "print(\"==========================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76a0b0-20a3-4de7-a967-9e011d84d708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edupy313",
   "language": "python",
   "name": "edupy313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
